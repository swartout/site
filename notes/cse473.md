---
title: CSE 473 (AI)
---

# CSE 473 (AI)

## Rob Minneker, Winter 2024

---

## Lecture 1 - Jan 3

- Grade is 50% PacMan projects, 50% written projects
- AI is the superset of ML, NNs, GenAI
- Went over all the fields of AI

---

## Lecture 2 - Jan 5

- A search problem cosists of:
    - State space
    - State transition function
    - State space graph
- We make search trees from our state space graphs, just paths from the graph
- Graphs with cycles become infinite search trees
- "Complete" search algorithm: always finds a solution if it exists
- "Optimal" search algorithm: always finds the shortest path between start and stop

**Search algos:**

- Uninformed
    - DFS, BFS
        - Same search method, different "fringe" (stack vs queue) goal
    - Uniform cost search (UCS):
        - Uses a priority queue
        - Complete and optimal
        - Similar to Dijkstra's
- Heuristics:
    - A *heuristic* estimates how close a state is to a goal
    - Admissibility:
        - Admissible (optimistic): $h(s) \geq 0$ and $h(s) \leq
          \text{true_cost}(s)$
        - Inadmissible (pessimistic) heuristics
    - Greedy search"
        - Use local heurstics
    - A\* search:
        - Order by sum of cost of path to get there plus heuristic
        - Optimal only with admissible heuristics

---

## Lecture 3 - Jan 8

**Adversarial search!**

- There are deterministic vs nondeterministic games, as well as perfect vs
  imperfect information games
- Terminal-utility games only give rewards at terminal states
- General games:
    - Agents have independent utilities
    - Agents can have range of behaviors, cooperative, adversarial, etc
- Zero-sum games:
    - Agents have opposite utilites
    - Agents are inherently adversaries
- Nash Equilibrium:
    - No agent can benefit by changing their strategy, assuming all other
      players strategies are fixed
    - Not necessarily optimal for all players, can be local optima
- MiniMax:
    - For two-player zero-sum (2PZS) games
    - Similar to BFS
    - One player maximizes score, other minimizes, taking turns
    - Assumes optimal play, is Nash
    - Implementation is recursive value function
- Alpha-beta pruning:
    - MiniMax with optimization
    - Keep track of alpha (max's best option on path to root) and beta (min's
      best option on path to root)
    - If we see options which will never be accepted, we can stop searching
      portions of the tree
    - "If we know min will return a value which is at least less than a value
      we know max can pick, max will never pick what min chooses here!"
    - Can double the solvable search depth
- In practice, depth-limited serach with evaluation functions is used

---

## Lecture 4 - Jan 10

- Expectimax:
    - Works with some randomness
    - Values in tree should represent the average case under optimal play, not
      worst case
    - Cannot use alpha-beta pruning except for domain-specific heuristics
    - Magnitudes must always scale, rewards don't depend just on being monotonic
- Multi-agent games:
    - Terminal states have tuple rewards
